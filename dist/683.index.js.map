{"version":3,"file":"683.index.js","mappings":";;;;;;;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC7FA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;AC5KA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACnDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC3DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACvSA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACtDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACrFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC3xBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA","sources":[".././node_modules/end-of-stream/index.js",".././node_modules/extract-zip/index.js",".././node_modules/extract-zip/node_modules/get-stream/buffer-stream.js",".././node_modules/extract-zip/node_modules/get-stream/index.js",".././node_modules/fd-slicer/index.js",".././node_modules/pend/index.js",".././node_modules/pump/index.js",".././node_modules/yauzl/index.js",".././node_modules/yauzl/node_modules/buffer-crc32/index.js"],"sourcesContent":["var once = require('once');\n\nvar noop = function() {};\n\nvar isRequest = function(stream) {\n\treturn stream.setHeader && typeof stream.abort === 'function';\n};\n\nvar isChildProcess = function(stream) {\n\treturn stream.stdio && Array.isArray(stream.stdio) && stream.stdio.length === 3\n};\n\nvar eos = function(stream, opts, callback) {\n\tif (typeof opts === 'function') return eos(stream, null, opts);\n\tif (!opts) opts = {};\n\n\tcallback = once(callback || noop);\n\n\tvar ws = stream._writableState;\n\tvar rs = stream._readableState;\n\tvar readable = opts.readable || (opts.readable !== false && stream.readable);\n\tvar writable = opts.writable || (opts.writable !== false && stream.writable);\n\tvar cancelled = false;\n\n\tvar onlegacyfinish = function() {\n\t\tif (!stream.writable) onfinish();\n\t};\n\n\tvar onfinish = function() {\n\t\twritable = false;\n\t\tif (!readable) callback.call(stream);\n\t};\n\n\tvar onend = function() {\n\t\treadable = false;\n\t\tif (!writable) callback.call(stream);\n\t};\n\n\tvar onexit = function(exitCode) {\n\t\tcallback.call(stream, exitCode ? new Error('exited with error code: ' + exitCode) : null);\n\t};\n\n\tvar onerror = function(err) {\n\t\tcallback.call(stream, err);\n\t};\n\n\tvar onclose = function() {\n\t\tprocess.nextTick(onclosenexttick);\n\t};\n\n\tvar onclosenexttick = function() {\n\t\tif (cancelled) return;\n\t\tif (readable && !(rs && (rs.ended && !rs.destroyed))) return callback.call(stream, new Error('premature close'));\n\t\tif (writable && !(ws && (ws.ended && !ws.destroyed))) return callback.call(stream, new Error('premature close'));\n\t};\n\n\tvar onrequest = function() {\n\t\tstream.req.on('finish', onfinish);\n\t};\n\n\tif (isRequest(stream)) {\n\t\tstream.on('complete', onfinish);\n\t\tstream.on('abort', onclose);\n\t\tif (stream.req) onrequest();\n\t\telse stream.on('request', onrequest);\n\t} else if (writable && !ws) { // legacy streams\n\t\tstream.on('end', onlegacyfinish);\n\t\tstream.on('close', onlegacyfinish);\n\t}\n\n\tif (isChildProcess(stream)) stream.on('exit', onexit);\n\n\tstream.on('end', onend);\n\tstream.on('finish', onfinish);\n\tif (opts.error !== false) stream.on('error', onerror);\n\tstream.on('close', onclose);\n\n\treturn function() {\n\t\tcancelled = true;\n\t\tstream.removeListener('complete', onfinish);\n\t\tstream.removeListener('abort', onclose);\n\t\tstream.removeListener('request', onrequest);\n\t\tif (stream.req) stream.req.removeListener('finish', onfinish);\n\t\tstream.removeListener('end', onlegacyfinish);\n\t\tstream.removeListener('close', onlegacyfinish);\n\t\tstream.removeListener('finish', onfinish);\n\t\tstream.removeListener('exit', onexit);\n\t\tstream.removeListener('end', onend);\n\t\tstream.removeListener('error', onerror);\n\t\tstream.removeListener('close', onclose);\n\t};\n};\n\nmodule.exports = eos;\n","const debug = require('debug')('extract-zip')\n// eslint-disable-next-line node/no-unsupported-features/node-builtins\nconst { createWriteStream, promises: fs } = require('fs')\nconst getStream = require('get-stream')\nconst path = require('path')\nconst { promisify } = require('util')\nconst stream = require('stream')\nconst yauzl = require('yauzl')\n\nconst openZip = promisify(yauzl.open)\nconst pipeline = promisify(stream.pipeline)\n\nclass Extractor {\n  constructor (zipPath, opts) {\n    this.zipPath = zipPath\n    this.opts = opts\n  }\n\n  async extract () {\n    debug('opening', this.zipPath, 'with opts', this.opts)\n\n    this.zipfile = await openZip(this.zipPath, { lazyEntries: true })\n    this.canceled = false\n\n    return new Promise((resolve, reject) => {\n      this.zipfile.on('error', err => {\n        this.canceled = true\n        reject(err)\n      })\n      this.zipfile.readEntry()\n\n      this.zipfile.on('close', () => {\n        if (!this.canceled) {\n          debug('zip extraction complete')\n          resolve()\n        }\n      })\n\n      this.zipfile.on('entry', async entry => {\n        /* istanbul ignore if */\n        if (this.canceled) {\n          debug('skipping entry', entry.fileName, { cancelled: this.canceled })\n          return\n        }\n\n        debug('zipfile entry', entry.fileName)\n\n        if (entry.fileName.startsWith('__MACOSX/')) {\n          this.zipfile.readEntry()\n          return\n        }\n\n        const destDir = path.dirname(path.join(this.opts.dir, entry.fileName))\n\n        try {\n          await fs.mkdir(destDir, { recursive: true })\n\n          const canonicalDestDir = await fs.realpath(destDir)\n          const relativeDestDir = path.relative(this.opts.dir, canonicalDestDir)\n\n          if (relativeDestDir.split(path.sep).includes('..')) {\n            throw new Error(`Out of bound path \"${canonicalDestDir}\" found while processing file ${entry.fileName}`)\n          }\n\n          await this.extractEntry(entry)\n          debug('finished processing', entry.fileName)\n          this.zipfile.readEntry()\n        } catch (err) {\n          this.canceled = true\n          this.zipfile.close()\n          reject(err)\n        }\n      })\n    })\n  }\n\n  async extractEntry (entry) {\n    /* istanbul ignore if */\n    if (this.canceled) {\n      debug('skipping entry extraction', entry.fileName, { cancelled: this.canceled })\n      return\n    }\n\n    if (this.opts.onEntry) {\n      this.opts.onEntry(entry, this.zipfile)\n    }\n\n    const dest = path.join(this.opts.dir, entry.fileName)\n\n    // convert external file attr int into a fs stat mode int\n    const mode = (entry.externalFileAttributes >> 16) & 0xFFFF\n    // check if it's a symlink or dir (using stat mode constants)\n    const IFMT = 61440\n    const IFDIR = 16384\n    const IFLNK = 40960\n    const symlink = (mode & IFMT) === IFLNK\n    let isDir = (mode & IFMT) === IFDIR\n\n    // Failsafe, borrowed from jsZip\n    if (!isDir && entry.fileName.endsWith('/')) {\n      isDir = true\n    }\n\n    // check for windows weird way of specifying a directory\n    // https://github.com/maxogden/extract-zip/issues/13#issuecomment-154494566\n    const madeBy = entry.versionMadeBy >> 8\n    if (!isDir) isDir = (madeBy === 0 && entry.externalFileAttributes === 16)\n\n    debug('extracting entry', { filename: entry.fileName, isDir: isDir, isSymlink: symlink })\n\n    const procMode = this.getExtractedMode(mode, isDir) & 0o777\n\n    // always ensure folders are created\n    const destDir = isDir ? dest : path.dirname(dest)\n\n    const mkdirOptions = { recursive: true }\n    if (isDir) {\n      mkdirOptions.mode = procMode\n    }\n    debug('mkdir', { dir: destDir, ...mkdirOptions })\n    await fs.mkdir(destDir, mkdirOptions)\n    if (isDir) return\n\n    debug('opening read stream', dest)\n    const readStream = await promisify(this.zipfile.openReadStream.bind(this.zipfile))(entry)\n\n    if (symlink) {\n      const link = await getStream(readStream)\n      debug('creating symlink', link, dest)\n      await fs.symlink(link, dest)\n    } else {\n      await pipeline(readStream, createWriteStream(dest, { mode: procMode }))\n    }\n  }\n\n  getExtractedMode (entryMode, isDir) {\n    let mode = entryMode\n    // Set defaults, if necessary\n    if (mode === 0) {\n      if (isDir) {\n        if (this.opts.defaultDirMode) {\n          mode = parseInt(this.opts.defaultDirMode, 10)\n        }\n\n        if (!mode) {\n          mode = 0o755\n        }\n      } else {\n        if (this.opts.defaultFileMode) {\n          mode = parseInt(this.opts.defaultFileMode, 10)\n        }\n\n        if (!mode) {\n          mode = 0o644\n        }\n      }\n    }\n\n    return mode\n  }\n}\n\nmodule.exports = async function (zipPath, opts) {\n  debug('creating target directory', opts.dir)\n\n  if (!path.isAbsolute(opts.dir)) {\n    throw new Error('Target directory is expected to be absolute')\n  }\n\n  await fs.mkdir(opts.dir, { recursive: true })\n  opts.dir = await fs.realpath(opts.dir)\n  return new Extractor(zipPath, opts).extract()\n}\n","'use strict';\nconst {PassThrough: PassThroughStream} = require('stream');\n\nmodule.exports = options => {\n\toptions = {...options};\n\n\tconst {array} = options;\n\tlet {encoding} = options;\n\tconst isBuffer = encoding === 'buffer';\n\tlet objectMode = false;\n\n\tif (array) {\n\t\tobjectMode = !(encoding || isBuffer);\n\t} else {\n\t\tencoding = encoding || 'utf8';\n\t}\n\n\tif (isBuffer) {\n\t\tencoding = null;\n\t}\n\n\tconst stream = new PassThroughStream({objectMode});\n\n\tif (encoding) {\n\t\tstream.setEncoding(encoding);\n\t}\n\n\tlet length = 0;\n\tconst chunks = [];\n\n\tstream.on('data', chunk => {\n\t\tchunks.push(chunk);\n\n\t\tif (objectMode) {\n\t\t\tlength = chunks.length;\n\t\t} else {\n\t\t\tlength += chunk.length;\n\t\t}\n\t});\n\n\tstream.getBufferedValue = () => {\n\t\tif (array) {\n\t\t\treturn chunks;\n\t\t}\n\n\t\treturn isBuffer ? Buffer.concat(chunks, length) : chunks.join('');\n\t};\n\n\tstream.getBufferedLength = () => length;\n\n\treturn stream;\n};\n","'use strict';\nconst {constants: BufferConstants} = require('buffer');\nconst pump = require('pump');\nconst bufferStream = require('./buffer-stream');\n\nclass MaxBufferError extends Error {\n\tconstructor() {\n\t\tsuper('maxBuffer exceeded');\n\t\tthis.name = 'MaxBufferError';\n\t}\n}\n\nasync function getStream(inputStream, options) {\n\tif (!inputStream) {\n\t\treturn Promise.reject(new Error('Expected a stream'));\n\t}\n\n\toptions = {\n\t\tmaxBuffer: Infinity,\n\t\t...options\n\t};\n\n\tconst {maxBuffer} = options;\n\n\tlet stream;\n\tawait new Promise((resolve, reject) => {\n\t\tconst rejectPromise = error => {\n\t\t\t// Don't retrieve an oversized buffer.\n\t\t\tif (error && stream.getBufferedLength() <= BufferConstants.MAX_LENGTH) {\n\t\t\t\terror.bufferedData = stream.getBufferedValue();\n\t\t\t}\n\n\t\t\treject(error);\n\t\t};\n\n\t\tstream = pump(inputStream, bufferStream(options), error => {\n\t\t\tif (error) {\n\t\t\t\trejectPromise(error);\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tresolve();\n\t\t});\n\n\t\tstream.on('data', () => {\n\t\t\tif (stream.getBufferedLength() > maxBuffer) {\n\t\t\t\trejectPromise(new MaxBufferError());\n\t\t\t}\n\t\t});\n\t});\n\n\treturn stream.getBufferedValue();\n}\n\nmodule.exports = getStream;\n// TODO: Remove this for the next major release\nmodule.exports.default = getStream;\nmodule.exports.buffer = (stream, options) => getStream(stream, {...options, encoding: 'buffer'});\nmodule.exports.array = (stream, options) => getStream(stream, {...options, array: true});\nmodule.exports.MaxBufferError = MaxBufferError;\n","var fs = require('fs');\nvar util = require('util');\nvar stream = require('stream');\nvar Readable = stream.Readable;\nvar Writable = stream.Writable;\nvar PassThrough = stream.PassThrough;\nvar Pend = require('pend');\nvar EventEmitter = require('events').EventEmitter;\n\nexports.createFromBuffer = createFromBuffer;\nexports.createFromFd = createFromFd;\nexports.BufferSlicer = BufferSlicer;\nexports.FdSlicer = FdSlicer;\n\nutil.inherits(FdSlicer, EventEmitter);\nfunction FdSlicer(fd, options) {\n  options = options || {};\n  EventEmitter.call(this);\n\n  this.fd = fd;\n  this.pend = new Pend();\n  this.pend.max = 1;\n  this.refCount = 0;\n  this.autoClose = !!options.autoClose;\n}\n\nFdSlicer.prototype.read = function(buffer, offset, length, position, callback) {\n  var self = this;\n  self.pend.go(function(cb) {\n    fs.read(self.fd, buffer, offset, length, position, function(err, bytesRead, buffer) {\n      cb();\n      callback(err, bytesRead, buffer);\n    });\n  });\n};\n\nFdSlicer.prototype.write = function(buffer, offset, length, position, callback) {\n  var self = this;\n  self.pend.go(function(cb) {\n    fs.write(self.fd, buffer, offset, length, position, function(err, written, buffer) {\n      cb();\n      callback(err, written, buffer);\n    });\n  });\n};\n\nFdSlicer.prototype.createReadStream = function(options) {\n  return new ReadStream(this, options);\n};\n\nFdSlicer.prototype.createWriteStream = function(options) {\n  return new WriteStream(this, options);\n};\n\nFdSlicer.prototype.ref = function() {\n  this.refCount += 1;\n};\n\nFdSlicer.prototype.unref = function() {\n  var self = this;\n  self.refCount -= 1;\n\n  if (self.refCount > 0) return;\n  if (self.refCount < 0) throw new Error(\"invalid unref\");\n\n  if (self.autoClose) {\n    fs.close(self.fd, onCloseDone);\n  }\n\n  function onCloseDone(err) {\n    if (err) {\n      self.emit('error', err);\n    } else {\n      self.emit('close');\n    }\n  }\n};\n\nutil.inherits(ReadStream, Readable);\nfunction ReadStream(context, options) {\n  options = options || {};\n  Readable.call(this, options);\n\n  this.context = context;\n  this.context.ref();\n\n  this.start = options.start || 0;\n  this.endOffset = options.end;\n  this.pos = this.start;\n  this.destroyed = false;\n}\n\nReadStream.prototype._read = function(n) {\n  var self = this;\n  if (self.destroyed) return;\n\n  var toRead = Math.min(self._readableState.highWaterMark, n);\n  if (self.endOffset != null) {\n    toRead = Math.min(toRead, self.endOffset - self.pos);\n  }\n  if (toRead <= 0) {\n    self.destroyed = true;\n    self.push(null);\n    self.context.unref();\n    return;\n  }\n  self.context.pend.go(function(cb) {\n    if (self.destroyed) return cb();\n    var buffer = new Buffer(toRead);\n    fs.read(self.context.fd, buffer, 0, toRead, self.pos, function(err, bytesRead) {\n      if (err) {\n        self.destroy(err);\n      } else if (bytesRead === 0) {\n        self.destroyed = true;\n        self.push(null);\n        self.context.unref();\n      } else {\n        self.pos += bytesRead;\n        self.push(buffer.slice(0, bytesRead));\n      }\n      cb();\n    });\n  });\n};\n\nReadStream.prototype.destroy = function(err) {\n  if (this.destroyed) return;\n  err = err || new Error(\"stream destroyed\");\n  this.destroyed = true;\n  this.emit('error', err);\n  this.context.unref();\n};\n\nutil.inherits(WriteStream, Writable);\nfunction WriteStream(context, options) {\n  options = options || {};\n  Writable.call(this, options);\n\n  this.context = context;\n  this.context.ref();\n\n  this.start = options.start || 0;\n  this.endOffset = (options.end == null) ? Infinity : +options.end;\n  this.bytesWritten = 0;\n  this.pos = this.start;\n  this.destroyed = false;\n\n  this.on('finish', this.destroy.bind(this));\n}\n\nWriteStream.prototype._write = function(buffer, encoding, callback) {\n  var self = this;\n  if (self.destroyed) return;\n\n  if (self.pos + buffer.length > self.endOffset) {\n    var err = new Error(\"maximum file length exceeded\");\n    err.code = 'ETOOBIG';\n    self.destroy();\n    callback(err);\n    return;\n  }\n  self.context.pend.go(function(cb) {\n    if (self.destroyed) return cb();\n    fs.write(self.context.fd, buffer, 0, buffer.length, self.pos, function(err, bytes) {\n      if (err) {\n        self.destroy();\n        cb();\n        callback(err);\n      } else {\n        self.bytesWritten += bytes;\n        self.pos += bytes;\n        self.emit('progress');\n        cb();\n        callback();\n      }\n    });\n  });\n};\n\nWriteStream.prototype.destroy = function() {\n  if (this.destroyed) return;\n  this.destroyed = true;\n  this.context.unref();\n};\n\nutil.inherits(BufferSlicer, EventEmitter);\nfunction BufferSlicer(buffer, options) {\n  EventEmitter.call(this);\n\n  options = options || {};\n  this.refCount = 0;\n  this.buffer = buffer;\n  this.maxChunkSize = options.maxChunkSize || Number.MAX_SAFE_INTEGER;\n}\n\nBufferSlicer.prototype.read = function(buffer, offset, length, position, callback) {\n  var end = position + length;\n  var delta = end - this.buffer.length;\n  var written = (delta > 0) ? delta : length;\n  this.buffer.copy(buffer, offset, position, end);\n  setImmediate(function() {\n    callback(null, written);\n  });\n};\n\nBufferSlicer.prototype.write = function(buffer, offset, length, position, callback) {\n  buffer.copy(this.buffer, position, offset, offset + length);\n  setImmediate(function() {\n    callback(null, length, buffer);\n  });\n};\n\nBufferSlicer.prototype.createReadStream = function(options) {\n  options = options || {};\n  var readStream = new PassThrough(options);\n  readStream.destroyed = false;\n  readStream.start = options.start || 0;\n  readStream.endOffset = options.end;\n  // by the time this function returns, we'll be done.\n  readStream.pos = readStream.endOffset || this.buffer.length;\n\n  // respect the maxChunkSize option to slice up the chunk into smaller pieces.\n  var entireSlice = this.buffer.slice(readStream.start, readStream.pos);\n  var offset = 0;\n  while (true) {\n    var nextOffset = offset + this.maxChunkSize;\n    if (nextOffset >= entireSlice.length) {\n      // last chunk\n      if (offset < entireSlice.length) {\n        readStream.write(entireSlice.slice(offset, entireSlice.length));\n      }\n      break;\n    }\n    readStream.write(entireSlice.slice(offset, nextOffset));\n    offset = nextOffset;\n  }\n\n  readStream.end();\n  readStream.destroy = function() {\n    readStream.destroyed = true;\n  };\n  return readStream;\n};\n\nBufferSlicer.prototype.createWriteStream = function(options) {\n  var bufferSlicer = this;\n  options = options || {};\n  var writeStream = new Writable(options);\n  writeStream.start = options.start || 0;\n  writeStream.endOffset = (options.end == null) ? this.buffer.length : +options.end;\n  writeStream.bytesWritten = 0;\n  writeStream.pos = writeStream.start;\n  writeStream.destroyed = false;\n  writeStream._write = function(buffer, encoding, callback) {\n    if (writeStream.destroyed) return;\n\n    var end = writeStream.pos + buffer.length;\n    if (end > writeStream.endOffset) {\n      var err = new Error(\"maximum file length exceeded\");\n      err.code = 'ETOOBIG';\n      writeStream.destroyed = true;\n      callback(err);\n      return;\n    }\n    buffer.copy(bufferSlicer.buffer, writeStream.pos, 0, buffer.length);\n\n    writeStream.bytesWritten += buffer.length;\n    writeStream.pos = end;\n    writeStream.emit('progress');\n    callback();\n  };\n  writeStream.destroy = function() {\n    writeStream.destroyed = true;\n  };\n  return writeStream;\n};\n\nBufferSlicer.prototype.ref = function() {\n  this.refCount += 1;\n};\n\nBufferSlicer.prototype.unref = function() {\n  this.refCount -= 1;\n\n  if (this.refCount < 0) {\n    throw new Error(\"invalid unref\");\n  }\n};\n\nfunction createFromBuffer(buffer, options) {\n  return new BufferSlicer(buffer, options);\n}\n\nfunction createFromFd(fd, options) {\n  return new FdSlicer(fd, options);\n}\n","module.exports = Pend;\n\nfunction Pend() {\n  this.pending = 0;\n  this.max = Infinity;\n  this.listeners = [];\n  this.waiting = [];\n  this.error = null;\n}\n\nPend.prototype.go = function(fn) {\n  if (this.pending < this.max) {\n    pendGo(this, fn);\n  } else {\n    this.waiting.push(fn);\n  }\n};\n\nPend.prototype.wait = function(cb) {\n  if (this.pending === 0) {\n    cb(this.error);\n  } else {\n    this.listeners.push(cb);\n  }\n};\n\nPend.prototype.hold = function() {\n  return pendHold(this);\n};\n\nfunction pendHold(self) {\n  self.pending += 1;\n  var called = false;\n  return onCb;\n  function onCb(err) {\n    if (called) throw new Error(\"callback called twice\");\n    called = true;\n    self.error = self.error || err;\n    self.pending -= 1;\n    if (self.waiting.length > 0 && self.pending < self.max) {\n      pendGo(self, self.waiting.shift());\n    } else if (self.pending === 0) {\n      var listeners = self.listeners;\n      self.listeners = [];\n      listeners.forEach(cbListener);\n    }\n  }\n  function cbListener(listener) {\n    listener(self.error);\n  }\n}\n\nfunction pendGo(self, fn) {\n  fn(pendHold(self));\n}\n","var once = require('once')\nvar eos = require('end-of-stream')\nvar fs\n\ntry {\n  fs = require('fs') // we only need fs to get the ReadStream and WriteStream prototypes\n} catch (e) {}\n\nvar noop = function () {}\nvar ancient = /^v?\\.0/.test(process.version)\n\nvar isFn = function (fn) {\n  return typeof fn === 'function'\n}\n\nvar isFS = function (stream) {\n  if (!ancient) return false // newer node version do not need to care about fs is a special way\n  if (!fs) return false // browser\n  return (stream instanceof (fs.ReadStream || noop) || stream instanceof (fs.WriteStream || noop)) && isFn(stream.close)\n}\n\nvar isRequest = function (stream) {\n  return stream.setHeader && isFn(stream.abort)\n}\n\nvar destroyer = function (stream, reading, writing, callback) {\n  callback = once(callback)\n\n  var closed = false\n  stream.on('close', function () {\n    closed = true\n  })\n\n  eos(stream, {readable: reading, writable: writing}, function (err) {\n    if (err) return callback(err)\n    closed = true\n    callback()\n  })\n\n  var destroyed = false\n  return function (err) {\n    if (closed) return\n    if (destroyed) return\n    destroyed = true\n\n    if (isFS(stream)) return stream.close(noop) // use close for fs streams to avoid fd leaks\n    if (isRequest(stream)) return stream.abort() // request.destroy just do .end - .abort is what we want\n\n    if (isFn(stream.destroy)) return stream.destroy()\n\n    callback(err || new Error('stream was destroyed'))\n  }\n}\n\nvar call = function (fn) {\n  fn()\n}\n\nvar pipe = function (from, to) {\n  return from.pipe(to)\n}\n\nvar pump = function () {\n  var streams = Array.prototype.slice.call(arguments)\n  var callback = isFn(streams[streams.length - 1] || noop) && streams.pop() || noop\n\n  if (Array.isArray(streams[0])) streams = streams[0]\n  if (streams.length < 2) throw new Error('pump requires two streams per minimum')\n\n  var error\n  var destroys = streams.map(function (stream, i) {\n    var reading = i < streams.length - 1\n    var writing = i > 0\n    return destroyer(stream, reading, writing, function (err) {\n      if (!error) error = err\n      if (err) destroys.forEach(call)\n      if (reading) return\n      destroys.forEach(call)\n      callback(error)\n    })\n  })\n\n  return streams.reduce(pipe)\n}\n\nmodule.exports = pump\n","var fs = require(\"fs\");\nvar zlib = require(\"zlib\");\nvar fd_slicer = require(\"fd-slicer\");\nvar crc32 = require(\"buffer-crc32\");\nvar util = require(\"util\");\nvar EventEmitter = require(\"events\").EventEmitter;\nvar Transform = require(\"stream\").Transform;\nvar PassThrough = require(\"stream\").PassThrough;\nvar Writable = require(\"stream\").Writable;\n\nexports.open = open;\nexports.fromFd = fromFd;\nexports.fromBuffer = fromBuffer;\nexports.fromRandomAccessReader = fromRandomAccessReader;\nexports.dosDateTimeToDate = dosDateTimeToDate;\nexports.validateFileName = validateFileName;\nexports.ZipFile = ZipFile;\nexports.Entry = Entry;\nexports.RandomAccessReader = RandomAccessReader;\n\nfunction open(path, options, callback) {\n  if (typeof options === \"function\") {\n    callback = options;\n    options = null;\n  }\n  if (options == null) options = {};\n  if (options.autoClose == null) options.autoClose = true;\n  if (options.lazyEntries == null) options.lazyEntries = false;\n  if (options.decodeStrings == null) options.decodeStrings = true;\n  if (options.validateEntrySizes == null) options.validateEntrySizes = true;\n  if (options.strictFileNames == null) options.strictFileNames = false;\n  if (callback == null) callback = defaultCallback;\n  fs.open(path, \"r\", function(err, fd) {\n    if (err) return callback(err);\n    fromFd(fd, options, function(err, zipfile) {\n      if (err) fs.close(fd, defaultCallback);\n      callback(err, zipfile);\n    });\n  });\n}\n\nfunction fromFd(fd, options, callback) {\n  if (typeof options === \"function\") {\n    callback = options;\n    options = null;\n  }\n  if (options == null) options = {};\n  if (options.autoClose == null) options.autoClose = false;\n  if (options.lazyEntries == null) options.lazyEntries = false;\n  if (options.decodeStrings == null) options.decodeStrings = true;\n  if (options.validateEntrySizes == null) options.validateEntrySizes = true;\n  if (options.strictFileNames == null) options.strictFileNames = false;\n  if (callback == null) callback = defaultCallback;\n  fs.fstat(fd, function(err, stats) {\n    if (err) return callback(err);\n    var reader = fd_slicer.createFromFd(fd, {autoClose: true});\n    fromRandomAccessReader(reader, stats.size, options, callback);\n  });\n}\n\nfunction fromBuffer(buffer, options, callback) {\n  if (typeof options === \"function\") {\n    callback = options;\n    options = null;\n  }\n  if (options == null) options = {};\n  options.autoClose = false;\n  if (options.lazyEntries == null) options.lazyEntries = false;\n  if (options.decodeStrings == null) options.decodeStrings = true;\n  if (options.validateEntrySizes == null) options.validateEntrySizes = true;\n  if (options.strictFileNames == null) options.strictFileNames = false;\n  // limit the max chunk size. see https://github.com/thejoshwolfe/yauzl/issues/87\n  var reader = fd_slicer.createFromBuffer(buffer, {maxChunkSize: 0x10000});\n  fromRandomAccessReader(reader, buffer.length, options, callback);\n}\n\nfunction fromRandomAccessReader(reader, totalSize, options, callback) {\n  if (typeof options === \"function\") {\n    callback = options;\n    options = null;\n  }\n  if (options == null) options = {};\n  if (options.autoClose == null) options.autoClose = true;\n  if (options.lazyEntries == null) options.lazyEntries = false;\n  if (options.decodeStrings == null) options.decodeStrings = true;\n  var decodeStrings = !!options.decodeStrings;\n  if (options.validateEntrySizes == null) options.validateEntrySizes = true;\n  if (options.strictFileNames == null) options.strictFileNames = false;\n  if (callback == null) callback = defaultCallback;\n  if (typeof totalSize !== \"number\") throw new Error(\"expected totalSize parameter to be a number\");\n  if (totalSize > Number.MAX_SAFE_INTEGER) {\n    throw new Error(\"zip file too large. only file sizes up to 2^52 are supported due to JavaScript's Number type being an IEEE 754 double.\");\n  }\n\n  // the matching unref() call is in zipfile.close()\n  reader.ref();\n\n  // eocdr means End of Central Directory Record.\n  // search backwards for the eocdr signature.\n  // the last field of the eocdr is a variable-length comment.\n  // the comment size is encoded in a 2-byte field in the eocdr, which we can't find without trudging backwards through the comment to find it.\n  // as a consequence of this design decision, it's possible to have ambiguous zip file metadata if a coherent eocdr was in the comment.\n  // we search backwards for a eocdr signature, and hope that whoever made the zip file was smart enough to forbid the eocdr signature in the comment.\n  var eocdrWithoutCommentSize = 22;\n  var maxCommentSize = 0xffff; // 2-byte size\n  var bufferSize = Math.min(eocdrWithoutCommentSize + maxCommentSize, totalSize);\n  var buffer = newBuffer(bufferSize);\n  var bufferReadStart = totalSize - buffer.length;\n  readAndAssertNoEof(reader, buffer, 0, bufferSize, bufferReadStart, function(err) {\n    if (err) return callback(err);\n    for (var i = bufferSize - eocdrWithoutCommentSize; i >= 0; i -= 1) {\n      if (buffer.readUInt32LE(i) !== 0x06054b50) continue;\n      // found eocdr\n      var eocdrBuffer = buffer.slice(i);\n\n      // 0 - End of central directory signature = 0x06054b50\n      // 4 - Number of this disk\n      var diskNumber = eocdrBuffer.readUInt16LE(4);\n      if (diskNumber !== 0) {\n        return callback(new Error(\"multi-disk zip files are not supported: found disk number: \" + diskNumber));\n      }\n      // 6 - Disk where central directory starts\n      // 8 - Number of central directory records on this disk\n      // 10 - Total number of central directory records\n      var entryCount = eocdrBuffer.readUInt16LE(10);\n      // 12 - Size of central directory (bytes)\n      // 16 - Offset of start of central directory, relative to start of archive\n      var centralDirectoryOffset = eocdrBuffer.readUInt32LE(16);\n      // 20 - Comment length\n      var commentLength = eocdrBuffer.readUInt16LE(20);\n      var expectedCommentLength = eocdrBuffer.length - eocdrWithoutCommentSize;\n      if (commentLength !== expectedCommentLength) {\n        return callback(new Error(\"invalid comment length. expected: \" + expectedCommentLength + \". found: \" + commentLength));\n      }\n      // 22 - Comment\n      // the encoding is always cp437.\n      var comment = decodeStrings ? decodeBuffer(eocdrBuffer, 22, eocdrBuffer.length, false)\n                                  : eocdrBuffer.slice(22);\n\n      if (!(entryCount === 0xffff || centralDirectoryOffset === 0xffffffff)) {\n        return callback(null, new ZipFile(reader, centralDirectoryOffset, totalSize, entryCount, comment, options.autoClose, options.lazyEntries, decodeStrings, options.validateEntrySizes, options.strictFileNames));\n      }\n\n      // ZIP64 format\n\n      // ZIP64 Zip64 end of central directory locator\n      var zip64EocdlBuffer = newBuffer(20);\n      var zip64EocdlOffset = bufferReadStart + i - zip64EocdlBuffer.length;\n      readAndAssertNoEof(reader, zip64EocdlBuffer, 0, zip64EocdlBuffer.length, zip64EocdlOffset, function(err) {\n        if (err) return callback(err);\n\n        // 0 - zip64 end of central dir locator signature = 0x07064b50\n        if (zip64EocdlBuffer.readUInt32LE(0) !== 0x07064b50) {\n          return callback(new Error(\"invalid zip64 end of central directory locator signature\"));\n        }\n        // 4 - number of the disk with the start of the zip64 end of central directory\n        // 8 - relative offset of the zip64 end of central directory record\n        var zip64EocdrOffset = readUInt64LE(zip64EocdlBuffer, 8);\n        // 16 - total number of disks\n\n        // ZIP64 end of central directory record\n        var zip64EocdrBuffer = newBuffer(56);\n        readAndAssertNoEof(reader, zip64EocdrBuffer, 0, zip64EocdrBuffer.length, zip64EocdrOffset, function(err) {\n          if (err) return callback(err);\n\n          // 0 - zip64 end of central dir signature                           4 bytes  (0x06064b50)\n          if (zip64EocdrBuffer.readUInt32LE(0) !== 0x06064b50) {\n            return callback(new Error(\"invalid zip64 end of central directory record signature\"));\n          }\n          // 4 - size of zip64 end of central directory record                8 bytes\n          // 12 - version made by                                             2 bytes\n          // 14 - version needed to extract                                   2 bytes\n          // 16 - number of this disk                                         4 bytes\n          // 20 - number of the disk with the start of the central directory  4 bytes\n          // 24 - total number of entries in the central directory on this disk         8 bytes\n          // 32 - total number of entries in the central directory            8 bytes\n          entryCount = readUInt64LE(zip64EocdrBuffer, 32);\n          // 40 - size of the central directory                               8 bytes\n          // 48 - offset of start of central directory with respect to the starting disk number     8 bytes\n          centralDirectoryOffset = readUInt64LE(zip64EocdrBuffer, 48);\n          // 56 - zip64 extensible data sector                                (variable size)\n          return callback(null, new ZipFile(reader, centralDirectoryOffset, totalSize, entryCount, comment, options.autoClose, options.lazyEntries, decodeStrings, options.validateEntrySizes, options.strictFileNames));\n        });\n      });\n      return;\n    }\n    callback(new Error(\"end of central directory record signature not found\"));\n  });\n}\n\nutil.inherits(ZipFile, EventEmitter);\nfunction ZipFile(reader, centralDirectoryOffset, fileSize, entryCount, comment, autoClose, lazyEntries, decodeStrings, validateEntrySizes, strictFileNames) {\n  var self = this;\n  EventEmitter.call(self);\n  self.reader = reader;\n  // forward close events\n  self.reader.on(\"error\", function(err) {\n    // error closing the fd\n    emitError(self, err);\n  });\n  self.reader.once(\"close\", function() {\n    self.emit(\"close\");\n  });\n  self.readEntryCursor = centralDirectoryOffset;\n  self.fileSize = fileSize;\n  self.entryCount = entryCount;\n  self.comment = comment;\n  self.entriesRead = 0;\n  self.autoClose = !!autoClose;\n  self.lazyEntries = !!lazyEntries;\n  self.decodeStrings = !!decodeStrings;\n  self.validateEntrySizes = !!validateEntrySizes;\n  self.strictFileNames = !!strictFileNames;\n  self.isOpen = true;\n  self.emittedError = false;\n\n  if (!self.lazyEntries) self._readEntry();\n}\nZipFile.prototype.close = function() {\n  if (!this.isOpen) return;\n  this.isOpen = false;\n  this.reader.unref();\n};\n\nfunction emitErrorAndAutoClose(self, err) {\n  if (self.autoClose) self.close();\n  emitError(self, err);\n}\nfunction emitError(self, err) {\n  if (self.emittedError) return;\n  self.emittedError = true;\n  self.emit(\"error\", err);\n}\n\nZipFile.prototype.readEntry = function() {\n  if (!this.lazyEntries) throw new Error(\"readEntry() called without lazyEntries:true\");\n  this._readEntry();\n};\nZipFile.prototype._readEntry = function() {\n  var self = this;\n  if (self.entryCount === self.entriesRead) {\n    // done with metadata\n    setImmediate(function() {\n      if (self.autoClose) self.close();\n      if (self.emittedError) return;\n      self.emit(\"end\");\n    });\n    return;\n  }\n  if (self.emittedError) return;\n  var buffer = newBuffer(46);\n  readAndAssertNoEof(self.reader, buffer, 0, buffer.length, self.readEntryCursor, function(err) {\n    if (err) return emitErrorAndAutoClose(self, err);\n    if (self.emittedError) return;\n    var entry = new Entry();\n    // 0 - Central directory file header signature\n    var signature = buffer.readUInt32LE(0);\n    if (signature !== 0x02014b50) return emitErrorAndAutoClose(self, new Error(\"invalid central directory file header signature: 0x\" + signature.toString(16)));\n    // 4 - Version made by\n    entry.versionMadeBy = buffer.readUInt16LE(4);\n    // 6 - Version needed to extract (minimum)\n    entry.versionNeededToExtract = buffer.readUInt16LE(6);\n    // 8 - General purpose bit flag\n    entry.generalPurposeBitFlag = buffer.readUInt16LE(8);\n    // 10 - Compression method\n    entry.compressionMethod = buffer.readUInt16LE(10);\n    // 12 - File last modification time\n    entry.lastModFileTime = buffer.readUInt16LE(12);\n    // 14 - File last modification date\n    entry.lastModFileDate = buffer.readUInt16LE(14);\n    // 16 - CRC-32\n    entry.crc32 = buffer.readUInt32LE(16);\n    // 20 - Compressed size\n    entry.compressedSize = buffer.readUInt32LE(20);\n    // 24 - Uncompressed size\n    entry.uncompressedSize = buffer.readUInt32LE(24);\n    // 28 - File name length (n)\n    entry.fileNameLength = buffer.readUInt16LE(28);\n    // 30 - Extra field length (m)\n    entry.extraFieldLength = buffer.readUInt16LE(30);\n    // 32 - File comment length (k)\n    entry.fileCommentLength = buffer.readUInt16LE(32);\n    // 34 - Disk number where file starts\n    // 36 - Internal file attributes\n    entry.internalFileAttributes = buffer.readUInt16LE(36);\n    // 38 - External file attributes\n    entry.externalFileAttributes = buffer.readUInt32LE(38);\n    // 42 - Relative offset of local file header\n    entry.relativeOffsetOfLocalHeader = buffer.readUInt32LE(42);\n\n    if (entry.generalPurposeBitFlag & 0x40) return emitErrorAndAutoClose(self, new Error(\"strong encryption is not supported\"));\n\n    self.readEntryCursor += 46;\n\n    buffer = newBuffer(entry.fileNameLength + entry.extraFieldLength + entry.fileCommentLength);\n    readAndAssertNoEof(self.reader, buffer, 0, buffer.length, self.readEntryCursor, function(err) {\n      if (err) return emitErrorAndAutoClose(self, err);\n      if (self.emittedError) return;\n      // 46 - File name\n      var isUtf8 = (entry.generalPurposeBitFlag & 0x800) !== 0;\n      entry.fileName = self.decodeStrings ? decodeBuffer(buffer, 0, entry.fileNameLength, isUtf8)\n                                          : buffer.slice(0, entry.fileNameLength);\n\n      // 46+n - Extra field\n      var fileCommentStart = entry.fileNameLength + entry.extraFieldLength;\n      var extraFieldBuffer = buffer.slice(entry.fileNameLength, fileCommentStart);\n      entry.extraFields = [];\n      var i = 0;\n      while (i < extraFieldBuffer.length - 3) {\n        var headerId = extraFieldBuffer.readUInt16LE(i + 0);\n        var dataSize = extraFieldBuffer.readUInt16LE(i + 2);\n        var dataStart = i + 4;\n        var dataEnd = dataStart + dataSize;\n        if (dataEnd > extraFieldBuffer.length) return emitErrorAndAutoClose(self, new Error(\"extra field length exceeds extra field buffer size\"));\n        var dataBuffer = newBuffer(dataSize);\n        extraFieldBuffer.copy(dataBuffer, 0, dataStart, dataEnd);\n        entry.extraFields.push({\n          id: headerId,\n          data: dataBuffer,\n        });\n        i = dataEnd;\n      }\n\n      // 46+n+m - File comment\n      entry.fileComment = self.decodeStrings ? decodeBuffer(buffer, fileCommentStart, fileCommentStart + entry.fileCommentLength, isUtf8)\n                                             : buffer.slice(fileCommentStart, fileCommentStart + entry.fileCommentLength);\n      // compatibility hack for https://github.com/thejoshwolfe/yauzl/issues/47\n      entry.comment = entry.fileComment;\n\n      self.readEntryCursor += buffer.length;\n      self.entriesRead += 1;\n\n      if (entry.uncompressedSize            === 0xffffffff ||\n          entry.compressedSize              === 0xffffffff ||\n          entry.relativeOffsetOfLocalHeader === 0xffffffff) {\n        // ZIP64 format\n        // find the Zip64 Extended Information Extra Field\n        var zip64EiefBuffer = null;\n        for (var i = 0; i < entry.extraFields.length; i++) {\n          var extraField = entry.extraFields[i];\n          if (extraField.id === 0x0001) {\n            zip64EiefBuffer = extraField.data;\n            break;\n          }\n        }\n        if (zip64EiefBuffer == null) {\n          return emitErrorAndAutoClose(self, new Error(\"expected zip64 extended information extra field\"));\n        }\n        var index = 0;\n        // 0 - Original Size          8 bytes\n        if (entry.uncompressedSize === 0xffffffff) {\n          if (index + 8 > zip64EiefBuffer.length) {\n            return emitErrorAndAutoClose(self, new Error(\"zip64 extended information extra field does not include uncompressed size\"));\n          }\n          entry.uncompressedSize = readUInt64LE(zip64EiefBuffer, index);\n          index += 8;\n        }\n        // 8 - Compressed Size        8 bytes\n        if (entry.compressedSize === 0xffffffff) {\n          if (index + 8 > zip64EiefBuffer.length) {\n            return emitErrorAndAutoClose(self, new Error(\"zip64 extended information extra field does not include compressed size\"));\n          }\n          entry.compressedSize = readUInt64LE(zip64EiefBuffer, index);\n          index += 8;\n        }\n        // 16 - Relative Header Offset 8 bytes\n        if (entry.relativeOffsetOfLocalHeader === 0xffffffff) {\n          if (index + 8 > zip64EiefBuffer.length) {\n            return emitErrorAndAutoClose(self, new Error(\"zip64 extended information extra field does not include relative header offset\"));\n          }\n          entry.relativeOffsetOfLocalHeader = readUInt64LE(zip64EiefBuffer, index);\n          index += 8;\n        }\n        // 24 - Disk Start Number      4 bytes\n      }\n\n      // check for Info-ZIP Unicode Path Extra Field (0x7075)\n      // see https://github.com/thejoshwolfe/yauzl/issues/33\n      if (self.decodeStrings) {\n        for (var i = 0; i < entry.extraFields.length; i++) {\n          var extraField = entry.extraFields[i];\n          if (extraField.id === 0x7075) {\n            if (extraField.data.length < 6) {\n              // too short to be meaningful\n              continue;\n            }\n            // Version       1 byte      version of this extra field, currently 1\n            if (extraField.data.readUInt8(0) !== 1) {\n              // > Changes may not be backward compatible so this extra\n              // > field should not be used if the version is not recognized.\n              continue;\n            }\n            // NameCRC32     4 bytes     File Name Field CRC32 Checksum\n            var oldNameCrc32 = extraField.data.readUInt32LE(1);\n            if (crc32.unsigned(buffer.slice(0, entry.fileNameLength)) !== oldNameCrc32) {\n              // > If the CRC check fails, this UTF-8 Path Extra Field should be\n              // > ignored and the File Name field in the header should be used instead.\n              continue;\n            }\n            // UnicodeName   Variable    UTF-8 version of the entry File Name\n            entry.fileName = decodeBuffer(extraField.data, 5, extraField.data.length, true);\n            break;\n          }\n        }\n      }\n\n      // validate file size\n      if (self.validateEntrySizes && entry.compressionMethod === 0) {\n        var expectedCompressedSize = entry.uncompressedSize;\n        if (entry.isEncrypted()) {\n          // traditional encryption prefixes the file data with a header\n          expectedCompressedSize += 12;\n        }\n        if (entry.compressedSize !== expectedCompressedSize) {\n          var msg = \"compressed/uncompressed size mismatch for stored file: \" + entry.compressedSize + \" != \" + entry.uncompressedSize;\n          return emitErrorAndAutoClose(self, new Error(msg));\n        }\n      }\n\n      if (self.decodeStrings) {\n        if (!self.strictFileNames) {\n          // allow backslash\n          entry.fileName = entry.fileName.replace(/\\\\/g, \"/\");\n        }\n        var errorMessage = validateFileName(entry.fileName, self.validateFileNameOptions);\n        if (errorMessage != null) return emitErrorAndAutoClose(self, new Error(errorMessage));\n      }\n      self.emit(\"entry\", entry);\n\n      if (!self.lazyEntries) self._readEntry();\n    });\n  });\n};\n\nZipFile.prototype.openReadStream = function(entry, options, callback) {\n  var self = this;\n  // parameter validation\n  var relativeStart = 0;\n  var relativeEnd = entry.compressedSize;\n  if (callback == null) {\n    callback = options;\n    options = {};\n  } else {\n    // validate options that the caller has no excuse to get wrong\n    if (options.decrypt != null) {\n      if (!entry.isEncrypted()) {\n        throw new Error(\"options.decrypt can only be specified for encrypted entries\");\n      }\n      if (options.decrypt !== false) throw new Error(\"invalid options.decrypt value: \" + options.decrypt);\n      if (entry.isCompressed()) {\n        if (options.decompress !== false) throw new Error(\"entry is encrypted and compressed, and options.decompress !== false\");\n      }\n    }\n    if (options.decompress != null) {\n      if (!entry.isCompressed()) {\n        throw new Error(\"options.decompress can only be specified for compressed entries\");\n      }\n      if (!(options.decompress === false || options.decompress === true)) {\n        throw new Error(\"invalid options.decompress value: \" + options.decompress);\n      }\n    }\n    if (options.start != null || options.end != null) {\n      if (entry.isCompressed() && options.decompress !== false) {\n        throw new Error(\"start/end range not allowed for compressed entry without options.decompress === false\");\n      }\n      if (entry.isEncrypted() && options.decrypt !== false) {\n        throw new Error(\"start/end range not allowed for encrypted entry without options.decrypt === false\");\n      }\n    }\n    if (options.start != null) {\n      relativeStart = options.start;\n      if (relativeStart < 0) throw new Error(\"options.start < 0\");\n      if (relativeStart > entry.compressedSize) throw new Error(\"options.start > entry.compressedSize\");\n    }\n    if (options.end != null) {\n      relativeEnd = options.end;\n      if (relativeEnd < 0) throw new Error(\"options.end < 0\");\n      if (relativeEnd > entry.compressedSize) throw new Error(\"options.end > entry.compressedSize\");\n      if (relativeEnd < relativeStart) throw new Error(\"options.end < options.start\");\n    }\n  }\n  // any further errors can either be caused by the zipfile,\n  // or were introduced in a minor version of yauzl,\n  // so should be passed to the client rather than thrown.\n  if (!self.isOpen) return callback(new Error(\"closed\"));\n  if (entry.isEncrypted()) {\n    if (options.decrypt !== false) return callback(new Error(\"entry is encrypted, and options.decrypt !== false\"));\n  }\n  // make sure we don't lose the fd before we open the actual read stream\n  self.reader.ref();\n  var buffer = newBuffer(30);\n  readAndAssertNoEof(self.reader, buffer, 0, buffer.length, entry.relativeOffsetOfLocalHeader, function(err) {\n    try {\n      if (err) return callback(err);\n      // 0 - Local file header signature = 0x04034b50\n      var signature = buffer.readUInt32LE(0);\n      if (signature !== 0x04034b50) {\n        return callback(new Error(\"invalid local file header signature: 0x\" + signature.toString(16)));\n      }\n      // all this should be redundant\n      // 4 - Version needed to extract (minimum)\n      // 6 - General purpose bit flag\n      // 8 - Compression method\n      // 10 - File last modification time\n      // 12 - File last modification date\n      // 14 - CRC-32\n      // 18 - Compressed size\n      // 22 - Uncompressed size\n      // 26 - File name length (n)\n      var fileNameLength = buffer.readUInt16LE(26);\n      // 28 - Extra field length (m)\n      var extraFieldLength = buffer.readUInt16LE(28);\n      // 30 - File name\n      // 30+n - Extra field\n      var localFileHeaderEnd = entry.relativeOffsetOfLocalHeader + buffer.length + fileNameLength + extraFieldLength;\n      var decompress;\n      if (entry.compressionMethod === 0) {\n        // 0 - The file is stored (no compression)\n        decompress = false;\n      } else if (entry.compressionMethod === 8) {\n        // 8 - The file is Deflated\n        decompress = options.decompress != null ? options.decompress : true;\n      } else {\n        return callback(new Error(\"unsupported compression method: \" + entry.compressionMethod));\n      }\n      var fileDataStart = localFileHeaderEnd;\n      var fileDataEnd = fileDataStart + entry.compressedSize;\n      if (entry.compressedSize !== 0) {\n        // bounds check now, because the read streams will probably not complain loud enough.\n        // since we're dealing with an unsigned offset plus an unsigned size,\n        // we only have 1 thing to check for.\n        if (fileDataEnd > self.fileSize) {\n          return callback(new Error(\"file data overflows file bounds: \" +\n              fileDataStart + \" + \" + entry.compressedSize + \" > \" + self.fileSize));\n        }\n      }\n      var readStream = self.reader.createReadStream({\n        start: fileDataStart + relativeStart,\n        end: fileDataStart + relativeEnd,\n      });\n      var endpointStream = readStream;\n      if (decompress) {\n        var destroyed = false;\n        var inflateFilter = zlib.createInflateRaw();\n        readStream.on(\"error\", function(err) {\n          // setImmediate here because errors can be emitted during the first call to pipe()\n          setImmediate(function() {\n            if (!destroyed) inflateFilter.emit(\"error\", err);\n          });\n        });\n        readStream.pipe(inflateFilter);\n\n        if (self.validateEntrySizes) {\n          endpointStream = new AssertByteCountStream(entry.uncompressedSize);\n          inflateFilter.on(\"error\", function(err) {\n            // forward zlib errors to the client-visible stream\n            setImmediate(function() {\n              if (!destroyed) endpointStream.emit(\"error\", err);\n            });\n          });\n          inflateFilter.pipe(endpointStream);\n        } else {\n          // the zlib filter is the client-visible stream\n          endpointStream = inflateFilter;\n        }\n        // this is part of yauzl's API, so implement this function on the client-visible stream\n        endpointStream.destroy = function() {\n          destroyed = true;\n          if (inflateFilter !== endpointStream) inflateFilter.unpipe(endpointStream);\n          readStream.unpipe(inflateFilter);\n          // TODO: the inflateFilter may cause a memory leak. see Issue #27.\n          readStream.destroy();\n        };\n      }\n      callback(null, endpointStream);\n    } finally {\n      self.reader.unref();\n    }\n  });\n};\n\nfunction Entry() {\n}\nEntry.prototype.getLastModDate = function() {\n  return dosDateTimeToDate(this.lastModFileDate, this.lastModFileTime);\n};\nEntry.prototype.isEncrypted = function() {\n  return (this.generalPurposeBitFlag & 0x1) !== 0;\n};\nEntry.prototype.isCompressed = function() {\n  return this.compressionMethod === 8;\n};\n\nfunction dosDateTimeToDate(date, time) {\n  var day = date & 0x1f; // 1-31\n  var month = (date >> 5 & 0xf) - 1; // 1-12, 0-11\n  var year = (date >> 9 & 0x7f) + 1980; // 0-128, 1980-2108\n\n  var millisecond = 0;\n  var second = (time & 0x1f) * 2; // 0-29, 0-58 (even numbers)\n  var minute = time >> 5 & 0x3f; // 0-59\n  var hour = time >> 11 & 0x1f; // 0-23\n\n  return new Date(year, month, day, hour, minute, second, millisecond);\n}\n\nfunction validateFileName(fileName) {\n  if (fileName.indexOf(\"\\\\\") !== -1) {\n    return \"invalid characters in fileName: \" + fileName;\n  }\n  if (/^[a-zA-Z]:/.test(fileName) || /^\\//.test(fileName)) {\n    return \"absolute path: \" + fileName;\n  }\n  if (fileName.split(\"/\").indexOf(\"..\") !== -1) {\n    return \"invalid relative path: \" + fileName;\n  }\n  // all good\n  return null;\n}\n\nfunction readAndAssertNoEof(reader, buffer, offset, length, position, callback) {\n  if (length === 0) {\n    // fs.read will throw an out-of-bounds error if you try to read 0 bytes from a 0 byte file\n    return setImmediate(function() { callback(null, newBuffer(0)); });\n  }\n  reader.read(buffer, offset, length, position, function(err, bytesRead) {\n    if (err) return callback(err);\n    if (bytesRead < length) {\n      return callback(new Error(\"unexpected EOF\"));\n    }\n    callback();\n  });\n}\n\nutil.inherits(AssertByteCountStream, Transform);\nfunction AssertByteCountStream(byteCount) {\n  Transform.call(this);\n  this.actualByteCount = 0;\n  this.expectedByteCount = byteCount;\n}\nAssertByteCountStream.prototype._transform = function(chunk, encoding, cb) {\n  this.actualByteCount += chunk.length;\n  if (this.actualByteCount > this.expectedByteCount) {\n    var msg = \"too many bytes in the stream. expected \" + this.expectedByteCount + \". got at least \" + this.actualByteCount;\n    return cb(new Error(msg));\n  }\n  cb(null, chunk);\n};\nAssertByteCountStream.prototype._flush = function(cb) {\n  if (this.actualByteCount < this.expectedByteCount) {\n    var msg = \"not enough bytes in the stream. expected \" + this.expectedByteCount + \". got only \" + this.actualByteCount;\n    return cb(new Error(msg));\n  }\n  cb();\n};\n\nutil.inherits(RandomAccessReader, EventEmitter);\nfunction RandomAccessReader() {\n  EventEmitter.call(this);\n  this.refCount = 0;\n}\nRandomAccessReader.prototype.ref = function() {\n  this.refCount += 1;\n};\nRandomAccessReader.prototype.unref = function() {\n  var self = this;\n  self.refCount -= 1;\n\n  if (self.refCount > 0) return;\n  if (self.refCount < 0) throw new Error(\"invalid unref\");\n\n  self.close(onCloseDone);\n\n  function onCloseDone(err) {\n    if (err) return self.emit('error', err);\n    self.emit('close');\n  }\n};\nRandomAccessReader.prototype.createReadStream = function(options) {\n  var start = options.start;\n  var end = options.end;\n  if (start === end) {\n    var emptyStream = new PassThrough();\n    setImmediate(function() {\n      emptyStream.end();\n    });\n    return emptyStream;\n  }\n  var stream = this._readStreamForRange(start, end);\n\n  var destroyed = false;\n  var refUnrefFilter = new RefUnrefFilter(this);\n  stream.on(\"error\", function(err) {\n    setImmediate(function() {\n      if (!destroyed) refUnrefFilter.emit(\"error\", err);\n    });\n  });\n  refUnrefFilter.destroy = function() {\n    stream.unpipe(refUnrefFilter);\n    refUnrefFilter.unref();\n    stream.destroy();\n  };\n\n  var byteCounter = new AssertByteCountStream(end - start);\n  refUnrefFilter.on(\"error\", function(err) {\n    setImmediate(function() {\n      if (!destroyed) byteCounter.emit(\"error\", err);\n    });\n  });\n  byteCounter.destroy = function() {\n    destroyed = true;\n    refUnrefFilter.unpipe(byteCounter);\n    refUnrefFilter.destroy();\n  };\n\n  return stream.pipe(refUnrefFilter).pipe(byteCounter);\n};\nRandomAccessReader.prototype._readStreamForRange = function(start, end) {\n  throw new Error(\"not implemented\");\n};\nRandomAccessReader.prototype.read = function(buffer, offset, length, position, callback) {\n  var readStream = this.createReadStream({start: position, end: position + length});\n  var writeStream = new Writable();\n  var written = 0;\n  writeStream._write = function(chunk, encoding, cb) {\n    chunk.copy(buffer, offset + written, 0, chunk.length);\n    written += chunk.length;\n    cb();\n  };\n  writeStream.on(\"finish\", callback);\n  readStream.on(\"error\", function(error) {\n    callback(error);\n  });\n  readStream.pipe(writeStream);\n};\nRandomAccessReader.prototype.close = function(callback) {\n  setImmediate(callback);\n};\n\nutil.inherits(RefUnrefFilter, PassThrough);\nfunction RefUnrefFilter(context) {\n  PassThrough.call(this);\n  this.context = context;\n  this.context.ref();\n  this.unreffedYet = false;\n}\nRefUnrefFilter.prototype._flush = function(cb) {\n  this.unref();\n  cb();\n};\nRefUnrefFilter.prototype.unref = function(cb) {\n  if (this.unreffedYet) return;\n  this.unreffedYet = true;\n  this.context.unref();\n};\n\nvar cp437 = '\\u0000☺☻♥♦♣♠•◘○◙♂♀♪♫☼►◄↕‼¶§▬↨↑↓→←∟↔▲▼ !\"#$%&\\'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\\\]^_`abcdefghijklmnopqrstuvwxyz{|}~⌂ÇüéâäàåçêëèïîìÄÅÉæÆôöòûùÿÖÜ¢£¥₧ƒáíóúñÑªº¿⌐¬½¼¡«»░▒▓│┤╡╢╖╕╣║╗╝╜╛┐└┴┬├─┼╞╟╚╔╩╦╠═╬╧╨╤╥╙╘╒╓╫╪┘┌█▄▌▐▀αßΓπΣσµτΦΘΩδ∞φε∩≡±≥≤⌠⌡÷≈°∙·√ⁿ²■ ';\nfunction decodeBuffer(buffer, start, end, isUtf8) {\n  if (isUtf8) {\n    return buffer.toString(\"utf8\", start, end);\n  } else {\n    var result = \"\";\n    for (var i = start; i < end; i++) {\n      result += cp437[buffer[i]];\n    }\n    return result;\n  }\n}\n\nfunction readUInt64LE(buffer, offset) {\n  // there is no native function for this, because we can't actually store 64-bit integers precisely.\n  // after 53 bits, JavaScript's Number type (IEEE 754 double) can't store individual integers anymore.\n  // but since 53 bits is a whole lot more than 32 bits, we do our best anyway.\n  var lower32 = buffer.readUInt32LE(offset);\n  var upper32 = buffer.readUInt32LE(offset + 4);\n  // we can't use bitshifting here, because JavaScript bitshifting only works on 32-bit integers.\n  return upper32 * 0x100000000 + lower32;\n  // as long as we're bounds checking the result of this function against the total file size,\n  // we'll catch any overflow errors, because we already made sure the total file size was within reason.\n}\n\n// Node 10 deprecated new Buffer().\nvar newBuffer;\nif (typeof Buffer.allocUnsafe === \"function\") {\n  newBuffer = function(len) {\n    return Buffer.allocUnsafe(len);\n  };\n} else {\n  newBuffer = function(len) {\n    return new Buffer(len);\n  };\n}\n\nfunction defaultCallback(err) {\n  if (err) throw err;\n}\n","var Buffer = require('buffer').Buffer;\n\nvar CRC_TABLE = [\n  0x00000000, 0x77073096, 0xee0e612c, 0x990951ba, 0x076dc419,\n  0x706af48f, 0xe963a535, 0x9e6495a3, 0x0edb8832, 0x79dcb8a4,\n  0xe0d5e91e, 0x97d2d988, 0x09b64c2b, 0x7eb17cbd, 0xe7b82d07,\n  0x90bf1d91, 0x1db71064, 0x6ab020f2, 0xf3b97148, 0x84be41de,\n  0x1adad47d, 0x6ddde4eb, 0xf4d4b551, 0x83d385c7, 0x136c9856,\n  0x646ba8c0, 0xfd62f97a, 0x8a65c9ec, 0x14015c4f, 0x63066cd9,\n  0xfa0f3d63, 0x8d080df5, 0x3b6e20c8, 0x4c69105e, 0xd56041e4,\n  0xa2677172, 0x3c03e4d1, 0x4b04d447, 0xd20d85fd, 0xa50ab56b,\n  0x35b5a8fa, 0x42b2986c, 0xdbbbc9d6, 0xacbcf940, 0x32d86ce3,\n  0x45df5c75, 0xdcd60dcf, 0xabd13d59, 0x26d930ac, 0x51de003a,\n  0xc8d75180, 0xbfd06116, 0x21b4f4b5, 0x56b3c423, 0xcfba9599,\n  0xb8bda50f, 0x2802b89e, 0x5f058808, 0xc60cd9b2, 0xb10be924,\n  0x2f6f7c87, 0x58684c11, 0xc1611dab, 0xb6662d3d, 0x76dc4190,\n  0x01db7106, 0x98d220bc, 0xefd5102a, 0x71b18589, 0x06b6b51f,\n  0x9fbfe4a5, 0xe8b8d433, 0x7807c9a2, 0x0f00f934, 0x9609a88e,\n  0xe10e9818, 0x7f6a0dbb, 0x086d3d2d, 0x91646c97, 0xe6635c01,\n  0x6b6b51f4, 0x1c6c6162, 0x856530d8, 0xf262004e, 0x6c0695ed,\n  0x1b01a57b, 0x8208f4c1, 0xf50fc457, 0x65b0d9c6, 0x12b7e950,\n  0x8bbeb8ea, 0xfcb9887c, 0x62dd1ddf, 0x15da2d49, 0x8cd37cf3,\n  0xfbd44c65, 0x4db26158, 0x3ab551ce, 0xa3bc0074, 0xd4bb30e2,\n  0x4adfa541, 0x3dd895d7, 0xa4d1c46d, 0xd3d6f4fb, 0x4369e96a,\n  0x346ed9fc, 0xad678846, 0xda60b8d0, 0x44042d73, 0x33031de5,\n  0xaa0a4c5f, 0xdd0d7cc9, 0x5005713c, 0x270241aa, 0xbe0b1010,\n  0xc90c2086, 0x5768b525, 0x206f85b3, 0xb966d409, 0xce61e49f,\n  0x5edef90e, 0x29d9c998, 0xb0d09822, 0xc7d7a8b4, 0x59b33d17,\n  0x2eb40d81, 0xb7bd5c3b, 0xc0ba6cad, 0xedb88320, 0x9abfb3b6,\n  0x03b6e20c, 0x74b1d29a, 0xead54739, 0x9dd277af, 0x04db2615,\n  0x73dc1683, 0xe3630b12, 0x94643b84, 0x0d6d6a3e, 0x7a6a5aa8,\n  0xe40ecf0b, 0x9309ff9d, 0x0a00ae27, 0x7d079eb1, 0xf00f9344,\n  0x8708a3d2, 0x1e01f268, 0x6906c2fe, 0xf762575d, 0x806567cb,\n  0x196c3671, 0x6e6b06e7, 0xfed41b76, 0x89d32be0, 0x10da7a5a,\n  0x67dd4acc, 0xf9b9df6f, 0x8ebeeff9, 0x17b7be43, 0x60b08ed5,\n  0xd6d6a3e8, 0xa1d1937e, 0x38d8c2c4, 0x4fdff252, 0xd1bb67f1,\n  0xa6bc5767, 0x3fb506dd, 0x48b2364b, 0xd80d2bda, 0xaf0a1b4c,\n  0x36034af6, 0x41047a60, 0xdf60efc3, 0xa867df55, 0x316e8eef,\n  0x4669be79, 0xcb61b38c, 0xbc66831a, 0x256fd2a0, 0x5268e236,\n  0xcc0c7795, 0xbb0b4703, 0x220216b9, 0x5505262f, 0xc5ba3bbe,\n  0xb2bd0b28, 0x2bb45a92, 0x5cb36a04, 0xc2d7ffa7, 0xb5d0cf31,\n  0x2cd99e8b, 0x5bdeae1d, 0x9b64c2b0, 0xec63f226, 0x756aa39c,\n  0x026d930a, 0x9c0906a9, 0xeb0e363f, 0x72076785, 0x05005713,\n  0x95bf4a82, 0xe2b87a14, 0x7bb12bae, 0x0cb61b38, 0x92d28e9b,\n  0xe5d5be0d, 0x7cdcefb7, 0x0bdbdf21, 0x86d3d2d4, 0xf1d4e242,\n  0x68ddb3f8, 0x1fda836e, 0x81be16cd, 0xf6b9265b, 0x6fb077e1,\n  0x18b74777, 0x88085ae6, 0xff0f6a70, 0x66063bca, 0x11010b5c,\n  0x8f659eff, 0xf862ae69, 0x616bffd3, 0x166ccf45, 0xa00ae278,\n  0xd70dd2ee, 0x4e048354, 0x3903b3c2, 0xa7672661, 0xd06016f7,\n  0x4969474d, 0x3e6e77db, 0xaed16a4a, 0xd9d65adc, 0x40df0b66,\n  0x37d83bf0, 0xa9bcae53, 0xdebb9ec5, 0x47b2cf7f, 0x30b5ffe9,\n  0xbdbdf21c, 0xcabac28a, 0x53b39330, 0x24b4a3a6, 0xbad03605,\n  0xcdd70693, 0x54de5729, 0x23d967bf, 0xb3667a2e, 0xc4614ab8,\n  0x5d681b02, 0x2a6f2b94, 0xb40bbe37, 0xc30c8ea1, 0x5a05df1b,\n  0x2d02ef8d\n];\n\nif (typeof Int32Array !== 'undefined') {\n  CRC_TABLE = new Int32Array(CRC_TABLE);\n}\n\nfunction ensureBuffer(input) {\n  if (Buffer.isBuffer(input)) {\n    return input;\n  }\n\n  var hasNewBufferAPI =\n      typeof Buffer.alloc === \"function\" &&\n      typeof Buffer.from === \"function\";\n\n  if (typeof input === \"number\") {\n    return hasNewBufferAPI ? Buffer.alloc(input) : new Buffer(input);\n  }\n  else if (typeof input === \"string\") {\n    return hasNewBufferAPI ? Buffer.from(input) : new Buffer(input);\n  }\n  else {\n    throw new Error(\"input must be buffer, number, or string, received \" +\n                    typeof input);\n  }\n}\n\nfunction bufferizeInt(num) {\n  var tmp = ensureBuffer(4);\n  tmp.writeInt32BE(num, 0);\n  return tmp;\n}\n\nfunction _crc32(buf, previous) {\n  buf = ensureBuffer(buf);\n  if (Buffer.isBuffer(previous)) {\n    previous = previous.readUInt32BE(0);\n  }\n  var crc = ~~previous ^ -1;\n  for (var n = 0; n < buf.length; n++) {\n    crc = CRC_TABLE[(crc ^ buf[n]) & 0xff] ^ (crc >>> 8);\n  }\n  return (crc ^ -1);\n}\n\nfunction crc32() {\n  return bufferizeInt(_crc32.apply(null, arguments));\n}\ncrc32.signed = function () {\n  return _crc32.apply(null, arguments);\n};\ncrc32.unsigned = function () {\n  return _crc32.apply(null, arguments) >>> 0;\n};\n\nmodule.exports = crc32;\n"],"names":[],"sourceRoot":""}